{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mohamedmaboshady/q-a-chatbot-gemini-fallback?scriptVersionId=250831649\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":null,"id":"324c2d57","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.003892,"end_time":"2025-07-16T11:41:37.113152","exception":false,"start_time":"2025-07-16T11:41:37.10926","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"5a8e4f2f","metadata":{"papermill":{"duration":0.002854,"end_time":"2025-07-16T11:41:37.119206","exception":false,"start_time":"2025-07-16T11:41:37.116352","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"27613e27","metadata":{"papermill":{"duration":0.002837,"end_time":"2025-07-16T11:41:37.124903","exception":false,"start_time":"2025-07-16T11:41:37.122066","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"id":"62cac04e","metadata":{"execution":{"iopub.execute_input":"2025-07-16T11:41:37.131725Z","iopub.status.busy":"2025-07-16T11:41:37.131456Z","iopub.status.idle":"2025-07-16T11:41:47.075148Z","shell.execute_reply":"2025-07-16T11:41:47.074271Z"},"papermill":{"duration":9.948996,"end_time":"2025-07-16T11:41:47.076759","exception":false,"start_time":"2025-07-16T11:41:37.127763","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\r\n","Collecting streamlit\r\n","  Downloading streamlit-1.46.1-py3-none-any.whl.metadata (9.0 kB)\r\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\r\n","Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\r\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (1.34.1)\r\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.173.0)\r\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.40.3)\r\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (3.20.3)\r\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\r\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\r\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\r\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\r\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\r\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\r\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\r\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\r\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\r\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\r\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\r\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (19.0.1)\r\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.4)\r\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\r\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\r\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\r\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\r\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\r\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\r\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.5.1)\r\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\r\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\r\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\r\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.44.0)\r\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\r\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\r\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\r\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\r\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->streamlit) (1.3.8)\r\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->streamlit) (1.2.4)\r\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->streamlit) (0.1.1)\r\n","Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->streamlit) (2025.2.0)\r\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->streamlit) (2022.2.0)\r\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->streamlit) (2.4.1)\r\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\r\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\r\n","Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\r\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\r\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\r\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\r\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\r\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\r\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\r\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\r\n","Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.49.0rc1)\r\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\r\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\r\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\r\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\r\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\r\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\r\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\r\n","Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.23->streamlit) (2024.2.0)\r\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.23->streamlit) (2022.2.0)\r\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.23->streamlit) (1.4.0)\r\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.23->streamlit) (2024.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.23->streamlit) (2024.2.0)\r\n","Downloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hInstalling collected packages: pydeck, streamlit\r\n","Successfully installed pydeck-0.9.1 streamlit-1.46.1\r\n","Copied /kaggle/input/q-a-fallback/medquad.csv to medquad.csv\n","Environment setup complete.\n"]}],"source":["\n","!pip install google-generativeai streamlit pandas\n","\n","import shutil\n","import os\n","import pandas as pd\n","# Define source and destination paths\n","source_csv_path = '/kaggle/input/q-a-fallback/medquad.csv'\n","destination_csv_path = 'medquad.csv' # This is the working directory\n","\n","# Check if the file already exists in the working directory to avoid unnecessary copying\n","if not os.path.exists(destination_csv_path):\n","    try:\n","        shutil.copy(source_csv_path, destination_csv_path)\n","        print(f\"Copied {source_csv_path} to {destination_csv_path}\")\n","    except FileNotFoundError:\n","        print(f\"Error: Source CSV not found at {source_csv_path}. Please ensure the dataset is added to your notebook.\")\n","    except Exception as e:\n","        print(f\"Error copying CSV: {e}\")\n","else:\n","    print(f\"{destination_csv_path} already exists in working directory. Skipping copy.\")\n","\n","print(\"Environment setup complete.\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"ffbb596b","metadata":{"papermill":{"duration":0.003924,"end_time":"2025-07-16T11:41:47.085876","exception":false,"start_time":"2025-07-16T11:41:47.081952","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"3c9e02d2","metadata":{"papermill":{"duration":0.003657,"end_time":"2025-07-16T11:41:47.093498","exception":false,"start_time":"2025-07-16T11:41:47.089841","status":"completed"},"tags":[]},"outputs":[],"source":["\n","\n"]},{"cell_type":"markdown","id":"541faae7","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2025-07-14T02:14:53.376837Z","iopub.status.busy":"2025-07-14T02:14:53.376309Z","iopub.status.idle":"2025-07-14T02:14:57.532247Z","shell.execute_reply":"2025-07-14T02:14:57.531731Z","shell.execute_reply.started":"2025-07-14T02:14:53.376799Z"},"jupyter":{"outputs_hidden":true},"papermill":{"duration":0.003816,"end_time":"2025-07-16T11:41:47.101033","exception":false,"start_time":"2025-07-16T11:41:47.097217","status":"completed"},"tags":[]},"source":["# app.py (This code would be in a separate .py file for Streamlit deployment\n","import streamlit as st\n","import os\n","import pandas as pd\n","import google.generativeai as genai\n","import re # Import regex for better keyword extraction\n","\n","# --- Configuration & Data Loading ---\n","try:\n","    # Attempt to get API key from environment variable (for Streamlit Cloud/local deployment)\n","    gemini_api_key = os.environ.get('GEMINI_API_KEY')\n","    if not gemini_api_key:\n","        # If running in Kaggle Notebook, try to get from Kaggle Secrets client\n","        # This part is specific to Kaggle Notebook environment\n","        try:\n","            from kaggle_secrets import UserSecretsClient\n","            user_secrets = UserSecretsClient()\n","            gemini_api_key = user_secrets.get_secret(\"GEMINI_API_KEY\")\n","        except ImportError:\n","            # Not in Kaggle environment, and env var not set\n","            st.error(\"GEMINI_API_KEY environment variable not found. Please set it.\")\n","            st.stop() # Stop the app if API key is missing\n","\n","    if not gemini_api_key:\n","        st.error(\"GEMINI_API_KEY is empty. Please ensure it's correctly set in Kaggle Secrets or environment variables.\")\n","        st.stop()\n","\n","    genai.configure(api_key=gemini_api_key)\n","    print(\"Gemini API configured successfully.\")\n","except Exception as e:\n","    st.error(f\"Error configuring Gemini API: {e}\")\n","    st.stop()\n","\n","# Load the Q&A dataset\n","@st.cache_data # Cache the dataframe loading to avoid re-reading on every rerun\n","def load_qa_data():\n","    try:\n","        data_path = 'medquad.csv' # Assuming it's in the same directory as app.py for Streamlit Cloud\n","        \n","        qa_df = pd.read_csv(data_path)\n","        \n","        \n","        expected_cols_mapping = {\n","            'question': 'Question', \n","            'answer': 'Answer', \n","            'focus_area': 'Focus Area'\n","        }\n","        \n","        for old_col, new_col in expected_cols_mapping.items():\n","            if old_col in qa_df.columns:\n","                qa_df.rename(columns={old_col: new_col}, inplace=True)\n","            elif new_col not in qa_df.columns: # Check if the new name exists directly\n","                st.error(f\"CSV must contain '{old_col}' or '{new_col}' column. Please check your file header.\")\n","                st.stop()\n","            \n","        print(f\"Dataset loaded successfully from {data_path}. Shape: {qa_df.shape}\")\n","        print(\"First 5 rows of your Q&A data (after potential renaming):\")\n","        print(qa_df.head())\n","        return qa_df\n","    except FileNotFoundError:\n","        st.error(f\"Dataset not found at {data_path}. Please ensure it's in the correct location.\")\n","        return pd.DataFrame(columns=['Question', 'Answer', 'Focus Area']) # Include Focus Area in empty df\n","    except Exception as e:\n","        st.error(f\"Error loading Q&A dataset: {e}\")\n","        return pd.DataFrame(columns=['Question', 'Answer', 'Focus Area'])\n","\n","qa_df = load_qa_data()\n","\n","# Initialize the Gemini 2.5 Flash model\n","@st.cache_resource # Cache the model to avoid re-initializing on every rerun\n","def load_gemini_model():\n","    return genai.GenerativeModel('gemini-2.5-flash')\n","\n","model = load_gemini_model()\n","\n","# --- Helper function to identify focus area ---\n","def identify_focus_area_from_question(user_question, qa_dataframe):\n","    \"\"\"\n","    Identifies the most probable focus area from the user's question based on keyword matching.\n","    Prioritizes direct focus area name matches within the user's question.\n","    Returns the identified focus area string or None.\n","    \"\"\"\n","    user_question_lower = user_question.lower()\n","    user_keywords = set(re.findall(r'\\b\\w+\\b', user_question_lower))\n","    \n","    identified_focus_area = None\n","    max_focus_score = 0 \n","    \n","    unique_focus_areas = qa_dataframe['Focus Area'].dropna().unique() # Get unique non-null focus areas\n","\n","    for focus_area_name in unique_focus_areas:\n","        focus_area_lower = str(focus_area_name).lower()\n","        \n","        current_score = 0\n","        \n","        # Strongest signal: if the user's question directly contains the focus area name\n","        if focus_area_lower in user_question_lower:\n","            current_score += 1000 # A very high bonus for direct containment\n","            current_score += len(focus_area_lower.split()) # Bonus for longer exact matches\n","\n","        # Fallback/additional signal: count keyword overlap\n","        current_score += sum(1 for keyword in user_keywords if keyword in focus_area_lower)\n","        \n","        if current_score > max_focus_score:\n","            max_focus_score = current_score\n","            identified_focus_area = focus_area_name\n","            \n","    return identified_focus_area # Returns None if no strong match\n","\n","\n","# --- Primary Retrieval function from dataset ---\n","def retrieve_context_from_dataset(user_question, qa_dataframe, top_n=3):\n","    \"\"\"\n","    Retrieves relevant Q&A pairs from the dataframe by first identifying a focus area,\n","    then performing keyword matching within that area.\n","    Returns a string of context, which might be empty if no relevant data is found.\n","    \"\"\"\n","    user_question_lower = user_question.lower()\n","    user_keywords = set(re.findall(r'\\b\\w+\\b', user_question_lower))\n","\n","    if qa_dataframe.empty or 'Question' not in qa_dataframe.columns or 'Answer' not in qa_dataframe.columns or 'Focus Area' not in qa_dataframe.columns:\n","        return \"Knowledge base is empty or required columns are missing. Cannot retrieve context.\"\n","\n","    # Identify the most probable focus area using the helper function\n","    identified_focus_area = identify_focus_area_from_question(user_question, qa_dataframe)\n","\n","    # Filter the DataFrame based on the identified focus area\n","    filtered_df = qa_dataframe\n","    if identified_focus_area: # Only filter if a relevant focus area was identified\n","        print(f\"Attempting to filter by identified focus area: '{identified_focus_area}'.\")\n","        # Case-insensitive filtering for the focus area\n","        temp_filtered_df = qa_dataframe[qa_dataframe['Focus Area'].str.lower() == identified_focus_area.lower()]\n","        \n","        if not temp_filtered_df.empty:\n","            filtered_df = temp_filtered_df\n","        else:\n","            print(f\"Filtering by '{identified_focus_area}' resulted in an empty DataFrame. Proceeding with full search.\")\n","\n","\n","    # Find relevant Q&A pairs within the (potentially filtered) DataFrame\n","    found_qa_pairs = []\n","    \n","    # Prioritize exact question match first from the filtered DataFrame\n","    exact_match_row = filtered_df[filtered_df['Question'].str.lower() == user_question_lower]\n","    if not exact_match_row.empty:\n","        found_qa_pairs.append(f\"Q: {exact_match_row.iloc[0]['Question']}\\nA: {exact_match_row.iloc[0]['Answer']}\")\n","        # If an exact match is found and we only need one, return it immediately\n","        if top_n == 1:\n","            return \"\\n\\n\".join(found_qa_pairs)\n","\n","    # Then, look for keyword matches in questions and answers within the filtered_df\n","    potential_matches = []\n","    for index, row in filtered_df.iterrows():\n","        qa_pair_string = f\"Q: {row['Question']}\\nA: {row['Answer']}\"\n","        # Skip if this is the exact match we already added\n","        if qa_pair_string in found_qa_pairs:\n","            continue\n","            \n","        question_text_lower = str(row['Question']).lower()\n","        answer_text_lower = str(row['Answer']).lower()\n","\n","        # Check for keyword overlap in question or answer\n","        keyword_overlap_count = sum(1 for keyword in user_keywords if keyword in question_text_lower or keyword in answer_text_lower)\n","        \n","        if keyword_overlap_count > 0: # Only add if there's at least one keyword overlap\n","            potential_matches.append((keyword_overlap_count, qa_pair_string))\n","\n","    # Sort potential matches by keyword overlap count (descending)\n","    potential_matches.sort(key=lambda x: x[0], reverse=True)\n","    \n","    # Add the top potential matches to found_qa_pairs until top_n is reached\n","    for count, qa_pair_string in potential_matches:\n","        if len(found_qa_pairs) < top_n:\n","            found_qa_pairs.append(qa_pair_string)\n","        else:\n","            break\n","\n","    # Return the context string. It will be empty if no relevant pairs were found.\n","    return \"\\n\\n\".join(found_qa_pairs)\n","\n","\n","# --- Chatbot response generation function with smart Gemini fallback ---\n","def generate_response_with_context(user_prompt, qa_dataframe):\n","    if model is None:\n","        return \"Chatbot not initialized. Please check API configuration.\"\n","    if qa_dataframe.empty:\n","        return \"Knowledge base is empty. Please load your Q&A dataset.\"\n","\n","    # 1. Attempt to retrieve context from the primary dataset\n","    context_from_dataset = retrieve_context_from_dataset(user_prompt, qa_dataframe)\n","    \n","    # Identify focus area for potential use in fallback or general guidance\n","    identified_focus_area = identify_focus_area_from_question(user_prompt, qa_dataframe)\n","    \n","    # Construct the base prompt for Gemini\n","    # This prompt is designed to allow Gemini to use its general knowledge if dataset context is weak.\n","    \n","    # If context from dataset is found, prioritize it.\n","    if context_from_dataset:\n","        print(\"Dataset context found. Using RAG prompt.\")\n","        full_prompt = f\"\"\"\n","        You are a helpful question-answering assistant specializing in medical topics.\n","        Use the following provided information to answer the user's question.\n","        If the provided information is incomplete or does not fully answer the question,\n","        you may supplement it with your general knowledge about the topic,\n","        especially if a focus area like '{identified_focus_area}' (if identified) is relevant.\n","        Do not make up answers if you truly don't know, even with general knowledge.\n","\n","        --- Provided Information ---\n","        {context_from_dataset}\n","        ---\n","\n","        User's Question: {user_prompt}\n","        \"\"\"\n","    else:\n","        # If no context from dataset, explicitly tell Gemini to use general knowledge\n","        # and guide it with the identified focus area if possible.\n","        print(\"No dataset context found. Falling back to Gemini's general knowledge.\")\n","        if identified_focus_area:\n","            full_prompt = f\"\"\"\n","            You are a helpful question-answering assistant specializing in medical topics.\n","            I could not find specific information in my knowledge base.\n","            Please answer the following question based on your general knowledge about '{identified_focus_area}'.\n","            If you truly don't know, state that you cannot answer.\n","\n","            User's Question: {user_prompt}\n","            \"\"\"\n","        else:\n","            # If no focus area identified either, just a general medical question\n","            full_prompt = f\"\"\"\n","            You are a helpful question-answering assistant specializing in medical topics.\n","            I could not find specific information in my knowledge base.\n","            Please answer the following question based on your general knowledge.\n","            If you truly don't know, state that you cannot answer.\n","\n","            User's Question: {user_prompt}\n","            \"\"\"\n","\n","    try:\n","        response = model.generate_content(full_prompt)\n","        final_response = response.text\n","    except Exception as e:\n","        print(f\"Error generating content from Gemini: {e}\")\n","        if hasattr(e, 'response') and e.response.prompt_feedback.block_reason:\n","            final_response = \"I'm sorry, I cannot answer that question due to content safety policies.\"\n","        else:\n","            final_response = \"I'm having trouble understanding or responding right now. Please try again.\"\n","    \n","    return final_response\n","\n","    # --- Streamlit UI ---\n","st.set_page_config(page_title=\"Custom Q&A Chatbot with Gemini 2.5 Flash\", layout=\"centered\")\n","\n","st.title(\"📚 Custom Q&A Chatbot (Powered by Gemini 2.5 Flash)\")\n","st.markdown(\"Ask questions based on the medical knowledge in my dataset! If I don't have specific data, I'll try to use my general knowledge for the topic.\")\n","\n","# Initialize chat history in session state\n","if \"messages\" not in st.session_state:\n","    st.session_state.messages = []\n","\n","# Display chat messages from history on app rerun\n","for message in st.session_state.messages:\n","    with st.chat_message(message[\"role\"]):\n","        st.markdown(message[\"content\"])\n","\n","# Accept user input\n","if prompt := st.chat_input(\"Ask your question here...\"):\n","    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n","    with st.chat_message(\"user\"):\n","        st.markdown(prompt)\n","\n","    with st.chat_message(\"assistant\"):\n","        with st.spinner(\"Thinking...\"):\n","            # Pass the loaded dataframe to the response generation function\n","            full_response = generate_response_with_context(prompt, qa_df)\n","        st.markdown(full_response)\n","    st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})\n","\n"]},{"cell_type":"code","execution_count":null,"id":"2f5d9771","metadata":{"papermill":{"duration":0.003729,"end_time":"2025-07-16T11:41:47.108547","exception":false,"start_time":"2025-07-16T11:41:47.104818","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"acf8ad9a","metadata":{"papermill":{"duration":0.00347,"end_time":"2025-07-16T11:41:47.116032","exception":false,"start_time":"2025-07-16T11:41:47.112562","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"a7d7d264","metadata":{"papermill":{"duration":0.003684,"end_time":"2025-07-16T11:41:47.123658","exception":false,"start_time":"2025-07-16T11:41:47.119974","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"4a66e30b","metadata":{"papermill":{"duration":0.003779,"end_time":"2025-07-16T11:41:47.132031","exception":false,"start_time":"2025-07-16T11:41:47.128252","status":"completed"},"tags":[]},"outputs":[],"source":["\n","\n"," \n","   \n","           \n","       \n","\n","\n","            "]},{"cell_type":"markdown","id":"c4be5b52","metadata":{"execution":{"iopub.execute_input":"2025-07-14T02:42:46.883079Z","iopub.status.busy":"2025-07-14T02:42:46.882775Z","iopub.status.idle":"2025-07-14T02:42:48.099699Z","shell.execute_reply":"2025-07-14T02:42:48.098946Z","shell.execute_reply.started":"2025-07-14T02:42:46.883049Z"},"papermill":{"duration":0.003612,"end_time":"2025-07-16T11:41:47.139312","exception":false,"start_time":"2025-07-16T11:41:47.1357","status":"completed"},"tags":[]},"source":["print(\"--- Chatbot Testing with CSV Context ---\")\n","\n","\n","# Example 1: Question directly from your CSV\n","question5 = \"What are the symptoms of sinusitis?\"\n","response5 = generate_response_with_context(question5, qa_df)\n","print(f\"question: {question5}\")\n","print(f\"Response: {response5}\\n\")\n"]},{"cell_type":"markdown","id":"e575e3b5","metadata":{"execution":{"iopub.status.busy":"2025-07-14T02:12:35.820451Z","iopub.status.idle":"2025-07-14T02:12:35.820668Z","shell.execute_reply":"2025-07-14T02:12:35.820562Z","shell.execute_reply.started":"2025-07-14T02:12:35.820553Z"},"papermill":{"duration":0.003833,"end_time":"2025-07-16T11:41:47.147241","exception":false,"start_time":"2025-07-16T11:41:47.143408","status":"completed"},"tags":[]},"source":["# Test the chatbot with various questions\n","print(\"--- Chatbot Testing with CSV Context ---\")\n","\n","# Assuming your qa_df has questions like \"What are the side effects of Drug X?\"\n","# and \"How do I schedule an appointment?\"\n","\n","# Example 1: Question directly from your CSV\n","question1 = \"What are the symptoms of high blood pressure?\"\n","response1 = generate_response_with_context(question1, qa_df)\n","print(f\"question: {question1}\")\n","print(f\"Response: {response1}\\n\")\n","\n","\n","# Example 2: A slightly rephrased question (testing retrieval)\n","question2 = \"what is the treament plan of Diabetes type 2.\"\n","response2 = generate_response_with_context(question2, qa_df)\n","print(f\"question: {question2}\")\n","print(f\"Response: {response2}\\n\")\n","\n","# Example 3: Question not directly in your CSV (testing fallback/general knowledge)\n","question3 = \"What is the capital of Japan?\"\n","response3 = generate_response_with_context(question3, qa_df)\n","print(f\"Question: {question3}\")\n","print(f\"Response: {response3}\\n\")\n","\n","# Example 4: Question that might retrieve general context if no direct match\n","question4 = \"What is the purpose of HIPAA?\"\n","response4 = generate_response_with_context(question4, qa_df)\n","print(f\"Question: {question4}\")\n","print(f\"Response: {response4}\\n\")\n","# Expected Response: If \"HIPAA\" is in your CSV, it should use that. Otherwise, it will rely on the fallback context.\n"]},{"cell_type":"markdown","id":"d56e13f0","metadata":{"execution":{"iopub.status.busy":"2025-07-14T02:12:35.821625Z","iopub.status.idle":"2025-07-14T02:12:35.821835Z","shell.execute_reply":"2025-07-14T02:12:35.821749Z","shell.execute_reply.started":"2025-07-14T02:12:35.821739Z"},"papermill":{"duration":0.003616,"end_time":"2025-07-16T11:41:47.15476","exception":false,"start_time":"2025-07-16T11:41:47.151144","status":"completed"},"tags":[]},"source":["# Example 2: A slightly rephrased question (testing retrieval)\n","question8 = \"what is the medicines of treament of Diabetes type 1 ,plz give me list of medicines and brands also.\"\n","response8 = generate_response_with_context(question8, qa_df)\n","print(f\"question: {question8}\")\n","print(f\"Response: {response8}\\n\")"]},{"cell_type":"markdown","id":"fc229cc2","metadata":{"execution":{"iopub.status.busy":"2025-07-14T02:12:35.823298Z","iopub.status.idle":"2025-07-14T02:12:35.823589Z","shell.execute_reply":"2025-07-14T02:12:35.823482Z","shell.execute_reply.started":"2025-07-14T02:12:35.823449Z"},"papermill":{"duration":0.003864,"end_time":"2025-07-16T11:41:47.162576","exception":false,"start_time":"2025-07-16T11:41:47.158712","status":"completed"},"tags":[]},"source":["# Example 2: A slightly rephrased question (testing retrieval)\n","question7 = \"what is the medicines of treament of Diabetes type 2.\"\n","response7 = generate_response_with_context(question7, qa_df)\n","print(f\"question: {question7}\")\n","print(f\"Response: {response7}\\n\")"]},{"cell_type":"code","execution_count":null,"id":"92603ce4","metadata":{"papermill":{"duration":0.003663,"end_time":"2025-07-16T11:41:47.169846","exception":false,"start_time":"2025-07-16T11:41:47.166183","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"fa1daf08","metadata":{"papermill":{"duration":0.003764,"end_time":"2025-07-16T11:41:47.177563","exception":false,"start_time":"2025-07-16T11:41:47.173799","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":7850445,"sourceId":12445212,"sourceType":"datasetVersion"}],"dockerImageVersionId":31090,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":16.378067,"end_time":"2025-07-16T11:41:47.599197","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-07-16T11:41:31.22113","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}